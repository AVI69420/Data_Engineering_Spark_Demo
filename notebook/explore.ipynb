{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pathlib import Path\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ExampleApp\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "user_df = spark.read.csv(\"users.csv\", header=True, inferSchema=True)\n",
    "transaction_df = spark.read.csv(\"transactions.csv\", header=True, inferSchema=True)  \n",
    "\n",
    "transaction_df = transaction_df.withColumn(\"timestamp\", F.to_date(\"timestamp\", \"yyyy-MM-dd\"))\n",
    "\n",
    "joined_df = user_df.join(transaction_df, on = \"user_id\", how = \"inner\")\n",
    "\n",
    "windowDriver = Window.partitionBy(\"user_id\").orderBy(F.asc(\"timestamp\"))\n",
    "\n",
    "joined_df = joined_df.withColumn(\"prev_date\", F.lag(\"timestamp\", 1).over(windowDriver))\n",
    "joined_df = joined_df.withColumn(\"date_diff\", F.dateDiff(F.col(\"timestamp\"), F.col(\"prev_date\")))\n",
    "\n",
    "result_df = joined_df.filter(\"date_diff > 30\")\n",
    "\n",
    "result_df.coalesce(1).write.parquet(\"output/date_diff.parquet\", mode=\"overwrite\")\n",
    "result_df.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
